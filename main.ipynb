{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import umap\nimport joblib\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.metrics import log_loss\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, FunctionTransformer\nfrom lightgbm import LGBMClassifier\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n\n\n# Function definition to create a CNN model\ndef create_cnn_model(N, n_features, n_classes):\n    model = Sequential()\n    model.add(Conv1D(N, kernel_size=3, activation='relu', input_shape=(n_features, 1)))\n    model.add(Dropout(0.3))\n    model.add(BatchNormalization())\n    model.add(MaxPooling1D(pool_size=2))\n    model.add(Conv1D(2*N, kernel_size=3, activation='relu'))\n    model.add(Dropout(0.4))\n    model.add(BatchNormalization())\n    model.add(MaxPooling1D(pool_size=2))\n    model.add(Flatten())\n    model.add(Dense(4*N, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(n_classes, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n    return model\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-10T20:34:55.137199Z","iopub.execute_input":"2023-09-10T20:34:55.137644Z","iopub.status.idle":"2023-09-10T20:34:55.152492Z","shell.execute_reply.started":"2023-09-10T20:34:55.137614Z","shell.execute_reply":"2023-09-10T20:34:55.151255Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Load the training data\ntrain_data = pd.read_csv(\"/kaggle/input/swc-interview/train_data_swc.csv\")\n# Extract the features (X) and target labels (y) from the training data\nX = train_data.drop(\"y\", axis=1)\ny = train_data[\"y\"]\n\n# Load the test data\nX_test = pd.read_csv(\"/kaggle/input/swc-interview/test_data_swc.csv\")\n\n# Split the training data into train and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1)\n\n# Standardize the data using the training data's statistics\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_val = scaler.transform(X_val)\nX_test = scaler.transform(X_test)\n\nn_classes = len(y.unique())     # Number of classes: 9\nassert n_classes == 9\nn_features = X_train.shape[1]   # Number of features: 108\nassert n_features == 108\nmodel_filename = \"stacking_model.pkl\"   # Define the filename for saving the model","metadata":{"execution":{"iopub.status.busy":"2023-09-10T20:34:55.154661Z","iopub.execute_input":"2023-09-10T20:34:55.155315Z","iopub.status.idle":"2023-09-10T20:34:57.689810Z","shell.execute_reply.started":"2023-09-10T20:34:55.155282Z","shell.execute_reply":"2023-09-10T20:34:57.688753Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# One-hot encode the target labels\n# y_train -= 1\n# y_val -= 1\n# y_train = to_categorical(y_train, num_classes=n_classes)\n# y_val = to_categorical(y_val, num_classes=n_classes)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T20:34:57.691297Z","iopub.execute_input":"2023-09-10T20:34:57.691672Z","iopub.status.idle":"2023-09-10T20:34:57.696361Z","shell.execute_reply.started":"2023-09-10T20:34:57.691636Z","shell.execute_reply":"2023-09-10T20:34:57.695241Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Define the parameter grid for hyperparameter tuning\nparams_grid_pipeline = {\n    \"umap__n_components\": [15, 25, 50],\n    \"umap__n_neighbors\": [5, 10, 20],\n    \"umap__min_dist\": [0.1, 0.2],\n}\n\n# Create a KerasClassifier with UMAP-transformed features\numap_model = umap.UMAP()\ncnn_model = KerasClassifier(build_fn=lambda: create_cnn_model(64, n_features, n_classes), verbose=0)\npipeline = Pipeline([(\"umap\", umap_model),\n                     (\"reshape\", FunctionTransformer(lambda x: np.reshape(x, (len(x), umap_model.n_components, 1)))),\n                     (\"cnn\", cnn_model)])\ngrid_search = GridSearchCV(estimator=pipeline, param_grid=params_grid_pipeline, cv=3, verbose=2, n_jobs=-1)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T20:34:57.699433Z","iopub.execute_input":"2023-09-10T20:34:57.700138Z","iopub.status.idle":"2023-09-10T20:34:57.710088Z","shell.execute_reply.started":"2023-09-10T20:34:57.700102Z","shell.execute_reply":"2023-09-10T20:34:57.709131Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_28/86101020.py:9: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n  cnn_model = KerasClassifier(build_fn=lambda: create_cnn_model(64, n_features, n_classes), verbose=0)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Fit the GridSearchCV to find the best hyperparameters\ngrid_search.fit(X_train, y_train)\n\n# Access the best hyperparameters\nbest_params = grid_search.best_params_","metadata":{"execution":{"iopub.status.busy":"2023-09-10T20:34:57.711516Z","iopub.execute_input":"2023-09-10T20:34:57.712037Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Fitting 3 folds for each of 18 candidates, totalling 54 fits\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n  @numba.jit()\n/opt/conda/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n  @numba.jit()\n/opt/conda/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n  @numba.jit()\n/opt/conda/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n  @numba.jit()\n/opt/conda/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n  @numba.jit()\n/opt/conda/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n  @numba.jit()\n/opt/conda/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n  @numba.jit()\n/opt/conda/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n  @numba.jit()\n/opt/conda/lib/python3.10/site-packages/sklearn/manifold/_spectral_embedding.py:274: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/manifold/_spectral_embedding.py:274: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/manifold/_spectral_embedding.py:274: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Apply UMAP to reduce dimensionality\numap_model = umap.UMAP(n_components=best_params['umap__n_components'],\n                       n_neighbors=best_params['umap__n_neighbors'], min_dist=best_params['umap__min_dist'])\nX_train = umap_model.fit_transform(X_train)\nX_val = umap_model.transform(X_val)\nX_test = umap_model.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the final CNN model with UMAP-transformed features\nfinal_model = create_cnn_model(64, best_params['umap__n_components'], n_classes)\n\n# Train the final model on the UMAP-transformed data\nfinal_model.fit(X_train, y_train, epochs=10, batch_size=32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create base models (CNNs) as scikit-learn estimators\n# base_models = [\n#     (\"cnn1\", KerasClassifier(build_fn=lambda: create_cnn_model(best_params['N'], best_params['n_components'], n_classes),\n#                              epochs=best_params['epochs'], batch_size=best_params['batch_size']))\n# ]\n\n# Define the stacking ensemble model\n# final_model = StackingClassifier(estimators=base_models, final_estimator=LGBMClassifier(n_estimators=30, n_jobs=-1, force_col_wise=True))\n\n# Fit the optimized model on the scaled training data\n# final_model.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the optimized model to a file\n# joblib.dump(final_model, model_filename)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on the scaled validation set using the optimized model\nval_predictions = final_model.predict(X_val)\n\n# Calculate prediction probabilities for validation predictions\nval_proba = final_model.predict_proba(X_val)\n\n# Clip predicted probabilities to avoid extremes of the log function\nval_proba = np.clip(val_proba, a_min=1e-15, a_max=1 - 1e-15)\n\n# Calculate log loss for validation predictions\nval_log_loss = log_loss(y_val, val_proba)\nprint(f\"Validation Log Loss: {val_log_loss:.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on the scaled test data using the optimized model\ntest_predictions = final_model.predict(X_test)\n\n# Calculate prediction probabilities for test predictions\ntest_proba = final_model.predict_proba(X_test)\n\n# Clip predicted probabilities to avoid extremes of the log function\ntest_proba = np.clip(test_proba, a_min=1e-15, a_max=1 - 1e-15)\n\n# Save the test predictions to a CSV file\nsubmission_df = pd.DataFrame(test_proba, columns=[f\"c{i}\" for i in range(1, n_classes + 1)])\nsubmission_df.to_csv(\"test_predictions.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}